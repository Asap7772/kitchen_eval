diff --git a/configs/action_ae/discretizers/k_means_bridge_kitchen.yaml b/configs/action_ae/discretizers/k_means_bridge_kitchen.yaml
new file mode 100644
index 0000000..59811f2
--- /dev/null
+++ b/configs/action_ae/discretizers/k_means_bridge_kitchen.yaml
@@ -0,0 +1,5 @@
+_target_: models.action_ae.discretizers.k_means.KMeansDiscretizer
+num_bins: 64
+action_dim: ${env.action_dim}
+device: ${device}
+predict_offsets: True
\ No newline at end of file
diff --git a/configs/encoder/resnet.yaml b/configs/encoder/resnet.yaml
index 468f925..bcb254e 100644
--- a/configs/encoder/resnet.yaml
+++ b/configs/encoder/resnet.yaml
@@ -1,4 +1,5 @@
-_target_: models.resnet.resnet18
-output_dim: 512
+_target_: models.resnet.resnet34
 pretrained: True
 freeze_pretrained: True
+output_dim: 512
+reproject_dim: 519
diff --git a/configs/env/block_pushing_multimodal_fixed_target.yaml b/configs/env/block_pushing_multimodal_fixed_target.yaml
index 4393352..836834c 100644
--- a/configs/env/block_pushing_multimodal_fixed_target.yaml
+++ b/configs/env/block_pushing_multimodal_fixed_target.yaml
@@ -1,4 +1,4 @@
-name: BlockPushMultimodal-v0
+name: BridgeKitchenDummyEnv-v0
 obs_dim: 16
 action_dim: 2
 action_min: null
diff --git a/configs/env/bridge_kitchen_traj.yaml b/configs/env/bridge_kitchen_traj.yaml
new file mode 100644
index 0000000..3c06e57
--- /dev/null
+++ b/configs/env/bridge_kitchen_traj.yaml
@@ -0,0 +1,23 @@
+name: bridge-dummmy-v0
+args: []
+kwargs: {}
+obs_dim: 512
+action_dim: 7
+action_min: [-1, -1]
+action_max: [1, 1]
+
+load_dir: "/absolute/path/to/training_run/directory"
+
+workspace:
+  _target_: workspaces.bridge_kitchen.BridgeRepWorkspace
+
+dataset_fn:
+  _target_: dataloaders.trajectory_loader.get_bridge_dataset
+  data_directory: ${env_vars.datasets.carla_multipath_town04_merge}
+  window_size: ${window_size}
+  subset_fraction: 1.0
+  encoder:
+    _target_: models.resnet.resnet18
+    output_dim: 512
+    pretrained: True
+    freeze_pretrained: True
diff --git a/configs/state_prior/mingpt_bridge_kitchen.yaml b/configs/state_prior/mingpt_bridge_kitchen.yaml
new file mode 100644
index 0000000..df58f13
--- /dev/null
+++ b/configs/state_prior/mingpt_bridge_kitchen.yaml
@@ -0,0 +1,20 @@
+_target_: models.latent_generators.mingpt.MinGPT
+
+discrete_input: false
+input_dim: ${encoder.output_dim}
+
+vocab_size: ???  # TBD by the discretization model.
+
+# Architecture details
+n_layer: 3
+n_head: 4
+n_embd: 256
+attn_pdrop: 0.6
+resid_pdrop: 0.6
+embd_pdrop: 0.6
+
+block_size: ${window_size}  # Length of history/context
+predict_offsets: True
+offset_loss_scale: 500.0
+focal_loss_gamma: 2.0
+action_dim: ${env.action_dim}
diff --git a/configs/train_bridge_kitchen.yaml b/configs/train_bridge_kitchen.yaml
new file mode 100644
index 0000000..be3df2c
--- /dev/null
+++ b/configs/train_bridge_kitchen.yaml
@@ -0,0 +1,54 @@
+defaults:
+  - _self_
+  - encoder: resnet
+  - action_ae: discretizers/k_means_bridge_kitchen
+  - env: bridge_kitchen_traj
+  - state_prior: mingpt_bridge_kitchen
+  - env_vars: env_vars
+
+lazy_init_models: True
+
+# Dataset details
+train_fraction: 0.95
+batch_size: 128
+num_workers: 32
+window_size: 10
+
+# Training details
+num_training_epochs: 1
+
+
+data_parallel: False
+device: cuda
+optim: Adam
+save_latents: False
+
+lr: 1e-4
+weight_decay: 0.1
+betas:
+  - 0.9
+  - 0.95
+grad_norm_clip: 1.0
+seed: 42
+
+# Prior training details
+num_prior_epochs: 40
+eval_prior_every: 1
+save_prior_every: 1
+
+# Logging frequency
+eval_every: 1
+save_every: 1
+
+# Wandb config
+project: behavior_transformer_test
+experiment: bridge_data
+
+hydra:
+  job:
+    override_dirname: ${experiment}
+  run:
+    dir: ./exp_local/${now:%Y.%m.%d}/${now:%H%M%S}_${experiment}
+  sweep:
+    dir: ./exp/${now:%Y.%m.%d}/${now:%H%M}_${experiment}
+    subdir: ${hydra.job.num}
diff --git a/dataloaders/trajectory_loader.py b/dataloaders/trajectory_loader.py
index 046de1d..113a97c 100644
--- a/dataloaders/trajectory_loader.py
+++ b/dataloaders/trajectory_loader.py
@@ -1,3 +1,4 @@
+from asyncio import tasks
 import logging
 import einops
 import os
@@ -17,6 +18,7 @@ from utils import (
 from typing import Union, Callable, Optional
 from tqdm import tqdm
 
+from envs.bridge_kitchen.get_bridge_tasks import get_bridge_tasks
 
 class RelayKitchenTrajectoryDataset(TensorDataset):
     def __init__(self, data_directory, device="cpu"):
@@ -48,6 +50,78 @@ class RelayKitchenTrajectoryDataset(TensorDataset):
         return torch.cat(result, dim=0)
 
 
+class BridgeTrajectoryDataset(Dataset):
+    def __init__(self, *args, task='all_pickplace_except_tk6', target_task='toykitchen6_croissant_out_of_pot', get_train=True, debug=True, **kwargs):
+        debug=True
+        if debug:
+            task='toykitchen6_drumstick_on_plate'
+        train_tasks, eval_tasks, target_train_tasks, target_eval_tasks = get_bridge_tasks(task, target_task)
+        
+        print("train_tasks", task)
+        print("eval_tasks", target_task)
+        print('UNUSED ARGS', args, kwargs)
+        
+        if get_train:
+            self.task_paths = train_tasks + target_train_tasks
+        else:
+            self.task_paths = eval_tasks + target_eval_tasks
+
+        tasks = []
+        for tp in self.task_paths:
+            print('loading task', tp)
+            tasks.append(np.load(tp, allow_pickle=True))
+        
+        num_tasks = len(tasks)
+        for i in range(num_tasks): # which task
+            for j in range(len(tasks[i])): # which trajectory
+                num_timesteps = len(tasks[i][j]['actions'])
+                tasks[i][j]['task_id'] = np.zeros((num_timesteps, num_tasks))
+                tasks[i][j]['task_id'][:, i] = 1
+        
+        self.data = np.concatenate(tasks, axis=0)
+    
+    def __len__(self):
+        return len(self.data)
+
+    def get_seq_length(self, idx):
+        return len(self.data[idx]['observations'])
+
+    def get_all_actions(self):
+        result = []
+        for i in range(len(self.data)):
+            T = len(self.data[i]['actions'])
+            result.append(torch.from_numpy(np.stack(self.data[i]['actions'])))
+        return torch.cat(result, dim=0)
+
+    def __getitem__(self, index) :
+        # observations: Tensor[N, T, C, H, W]
+        # actions: Tensor[N, T, C]
+        
+        curr_traj = self.data[index]
+        
+        observations = np.stack([x['images0'] for x in curr_traj['observations']])
+        observations = einops.rearrange(observations, 'n h w c -> n c h w')
+        actions = np.stack(curr_traj['actions'])
+        masks = np.ones(actions.shape[0]) # length of trajectory
+        task = curr_traj['task_id']
+        
+        assert len(observations) == len(actions) == len(masks) == len(task)
+        
+        return_val = (
+            observations,
+            actions,
+            masks,
+            task
+        )
+        
+        return_val = tuple([torch.from_numpy(x).float() for x in return_val])
+        
+        assert return_val[0].ndim == 4
+        
+        return return_val
+    
+        
+
 class CarlaMultipathTrajectoryDataset(Dataset):
     def __init__(
         self,
@@ -308,6 +382,7 @@ class TrajectorySlicerDataset(Dataset):
         self.transform = transform
         self.slices = []
         min_seq_length = np.inf
+        
         for i in range(len(self.dataset)):  # type: ignore
             T = self._get_seq_length(i)  # avoid reading actual seq (slow)
             min_seq_length = min(T, min_seq_length)
@@ -351,8 +426,8 @@ class TrajectorySlicerSubset(TrajectorySlicerDataset):
         # self.dataset is a torch.dataset.Subset, so we need to use the parent dataset
         # to extract the true seq length.
         subset = self.dataset
-        return subset.dataset.get_seq_length(subset.indices[idx])  # type: ignore
-
+        return subset.dataset.get_seq_length(idx)  # type: ignore
+            
     def _get_all_actions(self) -> torch.Tensor:
         return self.dataset.dataset.get_all_actions()
 
@@ -386,10 +461,17 @@ class TrajectoryRepDataset(Dataset):
         self.obs = []
         self.actions = []
         self.masks = []
+        self.tasks = []
         self.postprocess = postprocess
+        self.dataset = trajectory_dataset
         with eval_mode(encoder, no_grad=True):
             for i in tqdm(range(len(trajectory_dataset))):
-                obs, act, mask = trajectory_dataset[i]
+                tup = trajectory_dataset[i]
+                if len(tup) == 3:
+                    obs, act, mask = tup
+                    task = mask.unsqueeze(-1) # dummy task
+                else:
+                    obs, act, mask, task = tup
                 if preprocess is not None:
                     obs = preprocess(obs)
                 if batch_size is not None:
@@ -400,9 +482,10 @@ class TrajectoryRepDataset(Dataset):
                     obs_enc = torch.cat(obs_enc, dim=0)
                 else:
                     obs_enc = encoder(obs.to(self.device)).cpu()
-                self.obs.append(obs_enc)
-                self.actions.append(act)
-                self.masks.append(mask)
+                self.obs.append(obs_enc.float())
+                self.actions.append(act.float())
+                self.masks.append(mask.float())
+                self.tasks.append(task.float())
         del encoder
         torch.cuda.empty_cache()
 
@@ -413,7 +496,7 @@ class TrajectoryRepDataset(Dataset):
         obs = self.obs[idx]
         if self.postprocess is not None:
             obs = self.postprocess(obs)
-        return (obs, self.actions[idx], self.masks[idx])
+        return (obs, self.actions[idx], self.masks[idx], self.tasks[idx])
 
     def get_seq_length(self, idx):
         return int(self.masks[idx].sum().item())
@@ -566,3 +649,61 @@ def get_carla_multipath_rep_dataset(
     return TrajectorySlicerSubset(
         train_set, window=window_size
     ), TrajectorySlicerSubset(val_set, window=window_size)
+    
+    
+def get_bridge_dataset(
+    data_directory,
+    subset_fraction=1.0,
+    train_fraction=0.9,
+    random_seed=42,
+    device="cuda",
+    batch_size=None,
+    window_size=10,
+    task='all_pickplace_except_tk6', 
+    target_task='toykitchen6_croissant_out_of_pot',
+    debug=False,
+    encoder: nn.Module = nn.Identity,
+    preprocess: Callable[[torch.Tensor], torch.Tensor] = None,
+    postprocess: Callable[[torch.Tensor], torch.Tensor] = None,
+):
+    train_set = TrajectoryRepDataset(
+        BridgeTrajectoryDataset(
+            data_directory,
+            subset_fraction=subset_fraction,
+            device=device,
+            preprocess_to_float=False,
+            get_train=True,
+            task=task,
+            target_task=target_task,
+            debug=debug,
+        ),
+        encoder,
+        preprocess=preprocess,
+        postprocess=postprocess,
+        device=device,
+        batch_size=batch_size,
+    )
+    
+    val_set = TrajectoryRepDataset(
+        BridgeTrajectoryDataset(
+            data_directory,
+            subset_fraction=subset_fraction,
+            device=device,
+            preprocess_to_float=False,
+            get_train=False,
+            task=task,
+            target_task=target_task,
+            debug=debug,
+        ),
+        encoder,
+        preprocess=preprocess,
+        postprocess=postprocess,
+        device=device,
+        batch_size=batch_size,
+    )
+    
+    
+    return (
+        TrajectorySlicerSubset(train_set, window=window_size), 
+        TrajectorySlicerSubset(val_set, window=window_size)
+    )
diff --git a/envs/bridge_kitchen/dataset_config_real.py b/envs/bridge_kitchen/dataset_config_real.py
new file mode 100644
index 0000000..d5ce67b
--- /dev/null
+++ b/envs/bridge_kitchen/dataset_config_real.py
@@ -0,0 +1,114 @@
+import os
+os.environ['DATA'] = '/nfs/kun2/users/asap7772/'
+
+train_dataset_single_task = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/put_broccoli_in_pot_cardboardfence/train/out.npy']
+eval_dataset_single_task = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/put_broccoli_in_pot_cardboardfence/val/out.npy']
+
+
+train_dataset_single_task_openmicro = ['robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen5/open_microwave/train/out.npy']
+eval_dataset_single_task_openmicro = ['robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen5/open_microwave/val/out.npy']
+
+
+train_tasks = val_tasks = [
+    'put_broccoli_in_pot_cardboardfence',
+    'put_carrot_on_plate_cardboardfence',
+    'put_broccoli_in_pot_or_pan',
+    'put_broccoli_in_bowl',
+    'put_carrot_on_plate',
+    'put_sushi_on_plate',
+    'put_corn_into_bowl',
+    'put_sweet_potato_in_pan_which_is_on_stove',
+    'put_sweet_potato_in_pan_which_is_on_stove_distractors',
+    'put_sweet_potato_in_pot_which_is_in_sink_distractors',
+
+    'take_broccoli_out_of_pan_cardboardfence',
+    'take_carrot_off_plate_cardboardfence',
+    'take_broccoli_out_of_pan',
+    'take_can_out_of_pan',
+    'take_carrot_off_plate',
+    'take_lid_off_pot_or_pan',
+]
+
+# train_dataset_11_task = [f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8/toykitchen1/{task}/train/out.npy' for task in train_tasks]
+train_dataset_11_task = [f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/{task}/train/out.npy' for task in train_tasks]
+
+# eval_dataset_11_task = [f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8/toykitchen1/{task}/val/out.npy' for task in val_tasks]
+eval_dataset_11_task = [f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/{task}/val/out.npy' for task in val_tasks]
+
+train_tasks_tk5 = val_tasks_tk5 = [
+    'close_fridge',
+    'close_microwave',
+    'open_fridge',
+    'open_microwave',
+    'open_cabinet',
+    'open_low_fridge',
+    'open_oven',
+    'close_cabinet',
+    'close_low_fridge',
+    'close_oven',
+]
+
+train_tasks_tk6 = val_tasks_tk6 = [
+    'close_microwave',
+    'open_microwave',
+    'open_oven',
+    'close_oven',
+    'open_fridge',
+    'close_fridge',
+]
+
+
+train_dataset_openclose = [f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen5/{task}/train/out.npy' for task in train_tasks_tk5]
+train_dataset_openclose.extend([f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/{task}/train/out.npy' for task in train_tasks_tk6])
+train_dataset_openclose.extend([f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen6/{task}/train/out.npy' for task in train_tasks_tk6])
+eval_dataset_openclose = [f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen5/{task}/val/out.npy' for task in train_tasks_tk5]
+eval_dataset_openclose.extend([f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/{task}/val/out.npy' for task in train_tasks_tk6])
+eval_dataset_openclose.extend([f'robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen6/{task}/val/out.npy' for task in train_tasks_tk6])
+
+ALIASING_DICT = {
+        "flip_pot_upright_in_sink_distractors": "flip_pot_upright_which_is_in_sink",
+        "put_eggplant_into_pan": "put_eggplant_in_pot_or_pan",
+        "put_eggplant_into_pot_or_pan": "put_eggplant_in_pot_or_pan",
+        "faucet_front_to_left": "turn_faucet_front_to_left",
+        "put_cup_from_counter_or_drying_rack_into_sink": "put_cup_from_anywhere_into_sink",
+        "put_green_squash_into_pot_or_pan": "put_green_squash_in_pot_or_pan",
+        "turn_lever_vertical_to-front": "turn_lever_vertical_to_front",
+        "turn_lever_vertical_to_front_distractors": "turn_lever_vertical_to_front",
+        "put_pan_from_sink_into_drying_rack": "put_pot_or_pan_from_sink_into_drying_rack",
+        "put_corn_in_pan_which_is_on_stove_distractors": "put_corn_into_pot_or_pan",
+        "put_corn_in_pan_which-is_on_stove_distractors": "put_corn_into_pot_or_pan",
+        "put_corn_in_pot_which_is_in_sink_distractors": "put_corn_into_pot_or_pan",
+        "take_broccoli_out_of_pan": "take_broccoli_out_of_pot_or_pan",
+        "put_pepper_in_pan": "put_pepper_in_pot_or_pan",
+        "put_sweet_potato_in_pot_which_is_in_sink_distractors": "put_sweet_potato_in_pot",
+        "put_sweet_potato_in_pan_which_is_on_stove_distractors": "put_sweet_potato_in_pan_which_is_on_stove",
+        "put_pan_in_sink": "put_pot_or_pan_in_sink",
+        "put_pot_in_sink": "put_pot_or_pan_in_sink",
+        "put_pan_from_stove_to_sink": "put_pot_or_pan_in_sink",
+        "put_pot_on_stove_which_is_near_stove_distractors": "put_pot_or_pan_on_stove",
+        "put_pan_on_stove_from_sink": "put_pot_or_pan_on_stove",
+
+        "put_broccoli_in_pot_cardboardfence": "put_broccoli_in_pot_or_pan",
+        "put_carrot_on_plate_cardboardfence": "put_carrot_on_plate",
+        "take_broccoli_out_of_pan_cardboardfence": "take_broccoli_out_of_pot_or_pan",
+        "take_carrot_off_plate_cardboardfence": "take_carrot_off_plate",
+
+        'open_cabinet': 'open_door',
+        'open_oven': 'open_door',
+        'open_low_fridge': 'open_door',
+        'open_fridge': 'open_door',
+        'open_microwave': 'open_door',
+
+        'close_oven': 'close_door',
+        'close_fridge': 'close_door',
+        'close_cabinet': 'close_door',
+        'close_low_fridge': 'close_door',
+        'close_microwave': 'close_door'
+}
+
+# data from online reaching
+online_reaching_pixels_first100 = ['/robonetv2/online_datacollection/extract/online_reaching_first100/toykitchen1/pix_policy_std0.3_initscale0.0_collectdata/train/out.npy']
+online_reaching_pixels_val_first100 = ['/robonetv2/online_datacollection/extract/online_reaching_first100/toykitchen1/pix_policy_std0.3_initscale0.0_collectdata/val/out.npy']
+online_reaching_pixels= ['/robonetv2/online_datacollection/extract/online_reaching/toykitchen1/pix_policy_std0.3_initscale0.0_collectdata/train/out.npy']
+online_reaching_pixels_val= ['/robonetv2/online_datacollection/extract/online_reaching/toykitchen1/pix_policy_std0.3_initscale0.0_collectdata/val/out.npy']
+
diff --git a/envs/bridge_kitchen/dummy_env.py b/envs/bridge_kitchen/dummy_env.py
new file mode 100644
index 0000000..45f9a13
--- /dev/null
+++ b/envs/bridge_kitchen/dummy_env.py
@@ -0,0 +1,29 @@
+from gym.spaces import Box, Dict
+import numpy as np
+import gym
+
+class BridgeKitchenDummyEnv(gym.Env):
+    def __init__(self, from_states=False, add_states=False, num_tasks=1):
+        super().__init__()
+        obs_dict = dict()
+        if not from_states:
+            obs_dict['pixels'] = Box(low=0, high=255, shape=(128, 128, 3), dtype=np.uint8)
+        if add_states:
+            obs_dict['state'] = Box(low=-100000, high=100000, shape=(7,), dtype=np.float32)
+        if num_tasks > 1:
+            obs_dict['task_id'] = Box(low=0, high=1, shape=(num_tasks,), dtype=np.float32)
+        self.observation_space = Dict(obs_dict)
+        self.spec = None
+        self.action_space = Box(
+            np.asarray([-0.05, -0.05, -0.05, -0.25, -0.25, -0.25, 0.]),
+            np.asarray([0.05, 0.05, 0.05, 0.25, 0.25, 0.25, 1.0]),
+            dtype=np.float32)
+
+    def seed(self, seed):
+        pass
+    
+    def reset(self):
+        return self.observation_space.sample()
+
+    def step(self, action):
+        return self.observation_space.sample(), 0, False, {}
\ No newline at end of file
diff --git a/envs/bridge_kitchen/get_bridge_tasks.py b/envs/bridge_kitchen/get_bridge_tasks.py
new file mode 100644
index 0000000..77c85a1
--- /dev/null
+++ b/envs/bridge_kitchen/get_bridge_tasks.py
@@ -0,0 +1,114 @@
+from envs.bridge_kitchen.dataset_config_real import *
+from envs.bridge_kitchen.toykitchen_pickplace_dataset import *
+
+def get_bridge_tasks(dataset, target_dataset):
+    if dataset == 'single_task':
+        train_tasks = train_dataset_single_task
+        eval_tasks = eval_dataset_single_task
+    elif dataset =='11tasks':
+        print("using 11 tasks")
+        train_tasks = train_dataset_11_task
+        eval_tasks = eval_dataset_11_task
+    elif dataset == 'tk1_pickplace':
+        train_tasks, eval_tasks = get_toykitchen1_pickplace()
+    elif dataset == 'tk2_pickplace':
+        train_tasks, eval_tasks = get_toykitchen2_pickplace()
+    elif dataset == 'all_pickplace':
+        train_tasks, eval_tasks = get_all_pickplace()
+    elif dataset == 'open_micro_single':
+        train_tasks = train_dataset_single_task_openmicro
+        eval_tasks = eval_dataset_single_task_openmicro
+    elif dataset == 'online_reaching_pixels':
+        train_tasks = online_reaching_pixels
+        eval_tasks = online_reaching_pixels_val
+    elif dataset == 'online_reaching_pixels_first100':
+        train_tasks = online_reaching_pixels_first100
+        eval_tasks = online_reaching_pixels_val_first100
+    elif dataset == 'toykitchen1_pickplace':
+        train_tasks, eval_tasks = get_toykitchen1_pickplace()
+    elif dataset == 'toykitchen2_pickplace':
+        train_tasks, eval_tasks = get_toykitchen2_pickplace()
+    elif dataset == 'all_pickplace':
+        train_tasks, eval_tasks = get_all_pickplace()
+    elif dataset == 'all_pickplace_except_tk6':
+        train_tasks, eval_tasks = get_all_pickplace_exclude_tk6()
+    elif dataset == 'toykitchen2_pickplace_simpler':
+        train_tasks, eval_tasks = get_toykitchen2_pickplace_cardboardfence_reversible_simple()
+    elif dataset == 'toykitchen6_knife_in_pot':
+        train_tasks, eval_tasks = get_toykitchen6_knife_in_pot()
+    elif dataset == 'toykitchen6_croissant_out_of_pot':
+        train_tasks, eval_tasks = get_toykitchen6_croissant_out_of_pot()
+    elif dataset == 'toykitchen6_pear_from_plate':
+        train_tasks, eval_tasks = get_toyktichen6_pear_from_plate()
+    elif dataset == 'toykitchen6_sweet_potato_on_plate':
+        train_tasks, eval_tasks = get_toykitchen6_put_sweet_potato_on_plate()
+    elif dataset == 'toykitchen6_sweet_potato_in_bowl':
+        train_tasks, eval_tasks = get_toykitchen6_put_sweet_potato_in_bowl()
+    elif dataset == 'toykitchen6_lime_in_pan_sink':
+        train_tasks, eval_tasks = get_toyktichen6_put_lime_in_pan_sink()
+    elif dataset == 'toykitchen6_drumstick_on_plate':
+        train_tasks, eval_tasks = get_toykitchen6_put_drumstick_on_plate()
+    elif dataset == 'toykitchen6_cucumber_in_pot':
+        train_tasks, eval_tasks = get_toykitchen6_cucumber_in_orange_pot()
+    elif dataset == 'toykitchen6_carrot_in_pan':
+        train_tasks, eval_tasks = get_toykitchen6_carrot_in_pan()
+    elif dataset == 'debug':
+        num_debug_tasks = 3
+        train_tasks, eval_tasks = get_all_pickplace_exclude_tk6()
+        train_tasks = train_tasks[:num_debug_tasks]
+        eval_tasks = eval_tasks[:num_debug_tasks]
+    else:
+        raise ValueError('dataset not found! ' + dataset)
+
+    if target_dataset != '':
+        if target_dataset == 'toykitchen2_pickplace_cardboardfence_reversible':
+            target_train_tasks, target_eval_tasks = get_toykitchen2_pickplace_cardboardfence_reversible()
+            # target_train_tasks, target_eval_tasks = get_toykitchen2_pickplace_cardboardfence_reversible_simple()
+        elif target_dataset == 'toykitchen2_pickplace_simpler':
+            target_train_tasks, target_eval_tasks = get_toykitchen2_pickplace_cardboardfence_reversible_simple()
+        elif target_dataset == 'toykitchen6_pickplace_reversible':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_pickplace_reversible()
+        elif target_dataset == 'toykitchen6_target_domain':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_target_domain()
+        elif target_dataset == 'toykitchen6_new_target_domain':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_new_target_domain()
+        elif target_dataset == 'toykitchen6_target_domain_two_tasks':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_new_target_domain_2_tasks()
+        elif target_dataset == 'toykitchen6_target_domain_five_tasks':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_new_target_domain_5_tasks()
+        elif target_dataset == 'toykitchen6_knife_in_pot':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_knife_in_pot()
+        elif target_dataset == 'toykitchen6_croissant_out_of_pot':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_croissant_out_of_pot()
+        elif target_dataset == 'toykitchen6_pear_from_plate':
+            target_train_tasks, target_eval_tasks = get_toyktichen6_pear_from_plate()
+        elif target_dataset == 'toykitchen6_sweet_potato_on_plate':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_put_sweet_potato_on_plate()
+        elif target_dataset == 'toykitchen6_sweet_potato_in_bowl':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_put_sweet_potato_in_bowl()
+        elif target_dataset == 'toykitchen6_lime_in_pan_sink':
+            target_train_tasks, target_eval_tasks = get_toyktichen6_put_lime_in_pan_sink()
+        elif target_dataset == 'toykitchen6_drumstick_on_plate':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_put_drumstick_on_plate()
+        elif target_dataset == 'toykitchen6_cucumber_in_pot':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_cucumber_in_orange_pot()
+        elif target_dataset == 'toykitchen6_carrot_in_pan':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_carrot_in_pan()
+        elif target_dataset == 'toykitchen6_big_corn_in_big_pot':
+            target_train_tasks, target_eval_tasks = get_toykitchen6_big_corn_in_big_pot()
+        elif target_dataset == 'toykitchen1_pickplace_cardboardfence_reversible':
+            target_train_tasks, target_eval_tasks = get_toykitchen1_pickplace_cardboardfence_reversible()
+        elif target_dataset == 'toykitchen2_sushi_targetdomain':
+            target_train_tasks, target_eval_tasks = get_toykitchen2_sushi_targetdomain()
+        elif target_dataset == 'debug':
+            num_debug_tasks=1
+            target_train_tasks, target_eval_tasks = get_toykitchen2_pickplace_cardboardfence_reversible_simple()
+            target_train_tasks = target_train_tasks[:num_debug_tasks]
+            target_eval_tasks = target_eval_tasks[:num_debug_tasks]
+        else:
+            raise ValueError('target dataset not found! ' + target_dataset)
+    else:
+        target_train_tasks = []
+        target_eval_tasks = []
+
+    return train_tasks, eval_tasks, target_train_tasks, target_eval_tasks
\ No newline at end of file
diff --git a/envs/bridge_kitchen/toykitchen_pickplace_dataset.py b/envs/bridge_kitchen/toykitchen_pickplace_dataset.py
new file mode 100644
index 0000000..7118f9d
--- /dev/null
+++ b/envs/bridge_kitchen/toykitchen_pickplace_dataset.py
@@ -0,0 +1,273 @@
+import glob
+import os
+
+def exclude_tasks(paths, excluded_tasks):
+    new_paths = []
+    for d in paths:
+        reject = False
+        for exdir in excluded_tasks:
+            if exdir in d:
+                # print('excluding', d)
+                reject = True
+                break
+        if not reject:
+            new_paths.append(d)
+    return new_paths
+
+def include_tasks(paths, included_tasks):
+    new_paths = []
+    for d in paths:
+        accept = False
+        for exdir in included_tasks:
+            if exdir in d:
+                accept = True
+                break
+        if accept:
+            new_paths.append(d)
+    return new_paths
+
+def get_toykitchen2_pickplace():
+    tasks = glob.glob(os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen2/*')
+    tasks += glob.glob(os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen2_room8052/*')
+    exclude_list = ['zip', 'test', 'box', 'fold_cloth_in_half', 'put_cap_on_container', 'open_book', 'basil_bottle', 'flip',
+                    'topple', 'open', 'close', 'light_switch', 'upright', 'pour','drying_rack', 'faucet', 'turn']
+    tasks = exclude_tasks(tasks, exclude_list)
+    task_names = [str.split(path,  '/')[-1] for path in tasks]
+    print(task_names)
+
+    train = ['{}/train/out.npy'.format(task) for task in tasks]
+    val = ['{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen2_pickplace_cardboardfence_reversible():
+    tasks = ['put_lid_on_pot_cardboardfence',
+             'take_lid_off_pot_cardboardfence',
+             'put_bowl_on_plate_cardboard_fence',
+             'take_bowl_off_plate_cardboard_fence',
+             'put_sushi_in_pot_cardboard_fence',
+             'take_sushi_out_of_pot_cardboard_fence',
+             'put_carrot_in_pot_cardboard_fence',
+             'take_carrot_out_of_pot_cardboard_fence',
+             ]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen2/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen2/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+
+def get_toykitchen2_sushi_targetdomain():
+    tasks = ['put_sushi_in_pot_cardboard_fence', 'take_sushi_out_of_pot_cardboard_fence',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain/toykitchen2/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain/toykitchen2/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+
+
+
+def get_toykitchen2_pickplace_cardboardfence_reversible_simple():
+    tasks = ['put_lid_on_pot_cardboardfence',
+            #  'take_lid_off_pot_cardboardfence',
+             'put_bowl_on_plate_cardboard_fence',
+            #  'take_bowl_off_plate_cardboard_fence',
+             'put_sushi_in_pot_cardboard_fence',
+            #  'take_sushi_out_of_pot_cardboard_fence',
+             'put_carrot_in_pot_cardboard_fence',
+            #  'take_carrot_out_of_pot_cardboard_fence',
+             ]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen2/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen2/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_pickplace_reversible():
+    tasks = ['put_corn_in_bowl_sink',
+            'take_corn_out_of_bowl_sink',
+            'put_spoon_in_bowl_sink',
+            'take_spoon_out_of_bowl_sink',
+             'put_cup_on_plate',
+             'take_cup_off_plate'
+             ]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_target_domain():
+    tasks = ['put_knife_into_pot',
+             'take_croissant_out_of_pot',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-15/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-15/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_new_target_domain():
+    tasks = ['put_knife_into_pot',
+             'take_croissant_out_of_pot',
+             'take_pear_from_plate',
+             'put_sweet_potato_on_plate',
+             'put_lime_in_pan_sink',
+             'put_sweet_potato_in_bowl',
+             'put_drumstick_on_plate',
+             'put_cucumber_in_orange_pot',
+             'put_carrot_in_pan',
+             'put_big_corn_in_big_pot']
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+
+def get_toykitchen6_knife_in_pot():
+    tasks = ['put_knife_into_pot',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_croissant_out_of_pot():
+    tasks = ['take_croissant_out_of_pot',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toyktichen6_pear_from_plate():
+    tasks = ['take_pear_from_plate',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_put_sweet_potato_on_plate():
+    tasks = ['put_sweet_potato_on_plate',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_put_sweet_potato_in_bowl():
+    tasks = ['put_sweet_potato_in_bowl',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toyktichen6_put_lime_in_pan_sink():
+    tasks = ['put_lime_in_pan_sink',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_put_drumstick_on_plate():
+    tasks = ['put_drumstick_on_plate',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_cucumber_in_orange_pot():
+    tasks = ['put_cucumber_in_orange_pot',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_carrot_in_pan():
+    tasks = ['put_carrot_in_pan',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_big_corn_in_big_pot():
+    tasks = ['put_big_corn_in_big_pot',]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+
+
+def get_toykitchen6_new_target_domain_5_tasks():
+    tasks = ['put_knife_into_pot',
+             'take_croissant_out_of_pot',
+             'take_pear_from_plate',
+             'put_sweet_potato_on_plate',
+             'put_lime_in_pan_sink'
+    ]
+            #  'put_sweet_potato_in_bowl',
+            #  'put_drumstick_on_plate',
+            #  'put_cucumber_in_orange_pot',
+            #  'put_carrot_in_pan',
+            #  'put_big_corn_in_big_pot']
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen6_new_target_domain_2_tasks():
+    tasks = [
+        # 'put_knife_into_pot',
+            #  'take_croissant_out_of_pot',
+            #  'take_pear_from_plate',
+            #  'put_sweet_potato_on_plate',
+             'put_lime_in_pan_sink',
+            #  'put_sweet_potato_in_bowl',
+             'put_drumstick_on_plate',
+    ]
+            #  'put_cucumber_in_orange_pot',
+            #  'put_carrot_in_pan',
+            #  'put_big_corn_in_big_pot']
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/targetdomain_6-18/toykitchen6/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+
+
+def get_toykitchen1_pickplace():
+    tasks = glob.glob(os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/*')
+    exclude_list = ['test', 'box', 'basket', 'knob', 'open', 'close', 'flip', 'lever']
+    tasks = exclude_tasks(tasks, exclude_list)
+    task_names = [str.split(path,  '/')[-1] for path in tasks]
+    for name in task_names:
+        print(name)
+    print(len(task_names))
+
+    train = ['{}/train/out.npy'.format(task) for task in tasks]
+    val = ['{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_toykitchen1_pickplace_cardboardfence_reversible():
+    tasks = [
+        'put_broccoli_in_pan_cardboardfence',
+        'put_carrot_on_plate_cardboardfence',
+        'take_broccoli_out_of_pan_cardboardfence',
+        'take_carrot_off_plate_cardboardfence'
+    ]
+    train = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/{}/train/out.npy'.format(task) for task in tasks]
+    val = [os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/toykitchen1/{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+
+def get_all_pickplace():
+    tasks = glob.glob(os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/*/*')
+    exclude_list = ['zip', 'test', 'box', 'fold_cloth_in_half', 'put_cap_on_container', 'open_book', 'basil_bottle',
+                    'test', 'box', 'basket', 'knob', 'open', 'close', 'flip', 'lever', 'topple', 'pour', 'drying_rack'
+                    ]
+    tasks = exclude_tasks(tasks, exclude_list)
+    task_names = [str.split(path,  '/')[-2:] for path in tasks]
+    for name in task_names:
+        print(name)
+    print(len(task_names))
+
+    train = ['{}/train/out.npy'.format(task) for task in tasks]
+    val = ['{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+def get_all_pickplace_exclude_tk6():
+    tasks = glob.glob(os.environ['DATA'] + '/robonetv2/toykitchen_numpy_shifted/bridge_data_numpy_shifted_split_uint8_5-26/*/*')
+    exclude_list = ['zip', 'test', 'box', 'fold_cloth_in_half', 'put_cap_on_container', 'open_book', 'basil_bottle',
+                    'test', 'box', 'basket', 'knob', 'open', 'close', 'flip', 'lever', 'topple', 'pour', 'drying_rack',
+                    'tool_chest', 'laundry_machine']
+    exclude_list += ['toykitchen6']
+
+    tasks = exclude_tasks(tasks, exclude_list)
+    task_names = [str.split(path,  '/')[-2:] for path in tasks]
+    for name in task_names:
+        print(name)
+    print(len(task_names))
+
+    train = ['{}/train/out.npy'.format(task) for task in tasks]
+    val = ['{}/val/out.npy'.format(task) for task in tasks]
+    return train, val
+
+if __name__ == '__main__':
+    get_toykitchen1_pickplace()
+    # get_all_pickplace()
+    # get_toykitchen2_pickplace()
+    # get_toykitchen2_pickplace_cardboardfence_reversible()
diff --git a/models/action_ae/discretizers/k_means.py b/models/action_ae/discretizers/k_means.py
index 6c56125..b4dc63b 100644
--- a/models/action_ae/discretizers/k_means.py
+++ b/models/action_ae/discretizers/k_means.py
@@ -34,7 +34,7 @@ class KMeansDiscretizer(AbstractDiscretizer):
         cluster_centers = KMeansDiscretizer._kmeans(
             flattened_actions, ncluster=self.n_bins
         )
-        self.bin_centers = cluster_centers.to(self.device)
+        self.bin_centers = cluster_centers.to(self.device).float()
 
     @property
     def suggested_actions(self) -> torch.Tensor:
@@ -84,7 +84,6 @@ class KMeansDiscretizer(AbstractDiscretizer):
         assert (
             input_action.shape[-1] == self.action_dim
         ), "Input action dimension does not match fitted model"
-
         # flatten the input action
         flattened_actions = input_action.view(-1, self.action_dim)
 
diff --git a/models/resnet.py b/models/resnet.py
index f219c38..7e4aef2 100644
--- a/models/resnet.py
+++ b/models/resnet.py
@@ -10,6 +10,7 @@ class resnet18(nn.Module):
         pretrained: bool = True,
         freeze_pretrained: bool = True,
         output_dim: int = 512,  # fixed for resnet18; included for consistency with config
+        reproject_dim: int = 519,
     ):
         super().__init__()
         resnet = torchvision.models.resnet18(pretrained=pretrained)
@@ -22,6 +23,7 @@ class resnet18(nn.Module):
         self.normalize = torchvision.transforms.Normalize(
             mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
         )
+        self.linear_proj = nn.Linear(reproject_dim, output_dim)
 
     def forward(self, x):
         # if NTCHW, flatten to NCHW first
@@ -36,3 +38,38 @@ class resnet18(nn.Module):
         if is_seq:
             out = rearrange(out, "(n t) e -> n t e", n=n, t=t)
         return out
+
+class resnet34(nn.Module):
+    def __init__(
+        self,
+        pretrained: bool = True,
+        freeze_pretrained: bool = True,
+        output_dim: int = 512,  # fixed for resnet18; included for consistency with config
+        reproject_dim: int = 519,
+    ):
+        super().__init__()
+        resnet = torchvision.models.resnet34(pretrained=pretrained)
+        self.resnet = nn.Sequential(*list(resnet.children())[:-1])
+        self.flatten = nn.Flatten()
+        self.pretrained = pretrained
+        self.freeze_pretrained = pretrained and freeze_pretrained
+        if self.freeze_pretrained:
+            utils.freeze_module(self.resnet)
+        self.normalize = torchvision.transforms.Normalize(
+            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
+        )
+        self.linear_proj = nn.Linear(reproject_dim, output_dim)
+
+    def forward(self, x):
+        # if NTCHW, flatten to NCHW first
+        is_seq = x.dim() == 5
+        if is_seq:
+            n = x.shape[0]
+            t = x.shape[1]
+            x = rearrange(x, "n t c h w -> (n t) c h w")
+        x = self.normalize(x)
+        out = self.resnet(x)
+        out = self.flatten(out)
+        if is_seq:
+            out = rearrange(out, "(n t) e -> n t e", n=n, t=t)
+        return out
\ No newline at end of file
diff --git a/train.py b/train.py
index 0c316bd..9f4469a 100644
--- a/train.py
+++ b/train.py
@@ -120,10 +120,15 @@ class Workspace:
                 self.train_loader, desc=f"Training prior epoch {self.prior_epoch}"
             )
             for data in pbar:
-                observations, action, mask = data
+                observations, action, mask, task = data
                 self.state_prior_optimizer.zero_grad(set_to_none=True)
                 obs, act = observations.to(self.device), action.to(self.device)
-                enc_obs = self.obs_encoding_net(obs)
+                if obs.ndim != 3:
+                    enc_obs = self.obs_encoding_net(obs)
+                else:
+                    enc_obs = obs
+                enc_obs = torch.cat([enc_obs, act], dim=-1)
+                enc_obs = self.obs_encoding_net.linear_proj(enc_obs)
                 latent = self.action_ae.encode_into_latent(act, enc_obs)
                 _, loss, loss_components = self.state_prior.get_latent_and_loss(
                     obs_rep=enc_obs,
@@ -141,9 +146,12 @@ class Workspace:
         with utils.eval_mode(
             self.obs_encoding_net, self.action_ae, self.state_prior, no_grad=True
         ):
-            for observations, action, mask in self.test_loader:
+            for observations, action, mask, task in self.test_loader:
                 obs, act = observations.to(self.device), action.to(self.device)
-                enc_obs = self.obs_encoding_net(obs)
+                if obs.ndim != 3:
+                    enc_obs = self.obs_encoding_net(obs)
+                else:
+                    enc_obs = obs
                 latent = self.action_ae.encode_into_latent(act, enc_obs)
                 _, loss, loss_components = self.state_prior.get_latent_and_loss(
                     obs_rep=enc_obs,
diff --git a/workspaces/bridge_kitchen.py b/workspaces/bridge_kitchen.py
new file mode 100644
index 0000000..a8ff41c
--- /dev/null
+++ b/workspaces/bridge_kitchen.py
@@ -0,0 +1,40 @@
+import matplotlib.pyplot as plt
+import numpy as np
+import hydra
+
+import envs
+from workspaces import base
+
+
+class BridgeWorkspace(base.Workspace):
+    def __init__(self, cfg):
+        super().__init__(cfg)
+
+    def _setup_plots(self):
+        pass
+
+    def _setup_starting_state(self):
+        self.known_seeds = list(range(100))
+
+    def _start_from_known(self):
+        obs = self.env.reset(
+            seed=np.random.choice(self.known_seeds),
+        )
+        return obs
+
+    def _plot_obs_and_actions(self, obs, chosen_action, done, all_actions=None):
+        pass
+
+
+class BridgeRepWorkspace(BridgeWorkspace):
+    def __init__(self, cfg):
+        super().__init__(cfg)
+        # NOTE: bit of a hack; override snapshot and always use pretrained resnet18 as encoder.
+        # During training, we precompute all observation embeddings, and use the identity encoder.
+        # During evaluation, we use an actual pretrained resnet18 to encode the input RGB observations.
+        self.obs_encoding_net = hydra.utils.instantiate(cfg.encoder).to(self.device)
+
+
+class BridgeStateWorkspace(BridgeWorkspace):
+    def __init__(self, cfg):
+        super().__init__(cfg)
