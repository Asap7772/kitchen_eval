
K-means clustering:   0%|                                                                                                                                                                           | 0/50 [00:00<?, ?it/s]














K-means clustering:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 49/50 [00:28<00:00,  1.47it/s]
K-means clustering: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:29<00:00,  1.71it/s]
Training prior: :   0%|                                                                                                                                                                             | 0/40 [00:00<?, ?it/s]
Training prior: :   0%|                                                                                                                                                                             | 0/40 [00:33<?, ?it/s]
Error executing job with overrides: []
Traceback (most recent call last):
  File "train.py", line 292, in main
    workspace.run()
  File "train.py", line 191, in run
    self.train_prior()
  File "train.py", line 130, in train_prior
    enc_obs = torch.cat([enc_obs, task], dim=-1)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper___cat)
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.