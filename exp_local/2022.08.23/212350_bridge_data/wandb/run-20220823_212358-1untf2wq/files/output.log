K-means clustering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 218.36it/s]
Training prior: :   0%|                                                                                                                                                                                                                                                                        | 0/40 [00:00<?, ?it/s]
Training prior epoch 0:   0%|                                                                                                                                                                                                                                                                   | 0/8 [00:00<?, ?it/s]
done step 1/50, re-initialized 8 dead clusters
[2022-08-23 21:24:05,717][models.libraries.mingpt.model][INFO] - number of parameters: 2.634752e+06
> /nfs/kun2/users/asap7772/bet/exp_local/2022.08.23/212350_bridge_data/train.py(124)train_prior()

[?2004h[?1l[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?ipdb> n
[?7h[?12l[?25h[?2004l> /nfs/kun2/users/asap7772/bet/exp_local/2022.08.23/212350_bridge_data/train.py(125)train_prior()
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?ipdb> l
[?7h[?12l[?25h[?2004l[1m    120 [22m                self.train_loader, desc=f"Training prior epoch {self.prior_epoch}"
[1m    121 [22m            )
[1m    122 [22m            for data in pbar:
[1m    123 [22m                import ipdb; ipdb.set_trace()
[1m    124 [22m                observations, action, mask, task = data
--> 125                 self.state_prior_optimizer.zero_grad(set_to_none=True)
[1m    126 [22m                obs, act = observations.to(self.device), action.to(self.device)
[1m    127 [22m                enc_obs = self.obs_encoding_net(obs)
[1m    128 [22m                latent = self.action_ae.encode_into_latent(act, enc_obs)
[1m    129 [22m                _, loss, loss_components = self.state_prior.get_latent_and_loss(
[1m    130 [22m                    obs_rep=enc_obs,

[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7lt[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7lk[?7h[?12l[?25ipdb> task
[?7h[?12l[?25h[?2004ltensor([[[0., 1.],
         [0., 1.],
         [0., 1.],
         ...,
         [0., 1.],
         [0., 1.],
         [0., 1.]],
        [[0., 1.],
         [0., 1.],
         [0., 1.],
         ...,
         [0., 1.],
         [0., 1.],
         [0., 1.]],
        [[0., 1.],
         [0., 1.],
         [0., 1.],
         ...,
         [0., 1.],
         [0., 1.],
         [0., 1.]],
        ...,
        [[0., 1.],
         [0., 1.],
         [0., 1.],
         ...,
         [0., 1.],
         [0., 1.],
         [0., 1.]],
        [[0., 1.],
         [0., 1.],
         [0., 1.],
         ...,
         [0., 1.],
         [0., 1.],
         [0., 1.]],
        [[0., 1.],
         [0., 1.],
         [0., 1.],
         ...,
         [0., 1.],
         [0., 1.],
         [0., 1.]]])


[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7lt[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7l.[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7lh[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lp[?7h[?12l[?25h[?25l[?7le[?7h[?12l[?25h[?25l[?7[?7h[?12l[?25h[?25l[?7[?7h[?12l[?25h[?25l[?7[?7h[?12l[?25h[?25l[?7[?7h[?12l[?25h[?25l[?7[?7h[?12l[?25h[?25l[?7[?7h[?12l[?25h[?25l[?7lk[?7h[?12l[?25h[?25l[?7l.[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7lh[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lp[?7h[?12l[?25h[?25l[?7le[?7h[?1ipdb> task.shape
[?7h[?12l[?25h[?2004ltorch.Size([128, 10, 2])

[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7lo[?7h[?12l[?25h[?25l[?7lb[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7ler[?7h[?12l[?25h[?25l[?7lv[?7h[?12l[?25h[?25l[?7lat[?7h[?12l[?25h[?25l[?7li[?7h[?12l[?25h[?25l[?7lo[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?25l[?7ls.[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7lh[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lp[?7h[?12l[?25h[?25l[?7lipdb> observations.shape
[?7h[?12l[?25h[?2004ltorch.Size([128, 10, 512])
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?ipdb> n
[?7h[?12l[?25h[?2004l> /nfs/kun2/users/asap7772/bet/exp_local/2022.08.23/212350_bridge_data/train.py(126)train_prior()
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7lc[?7h[?12l[?25h[?25l[?7[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?ipdb> l
[?7h[?12l[?25h[?2004l[1m    121 [22m            )
[1m    122 [22m            for data in pbar:
[1m    123 [22m                import ipdb; ipdb.set_trace()
[1m    124 [22m                observations, action, mask, task = data
[1m    125 [22m                self.state_prior_optimizer.zero_grad(set_to_none=True)
--> 126                 obs, act = observations.to(self.device), action.to(self.device)
[1m    127 [22m                enc_obs = self.obs_encoding_net(obs)
[1m    128 [22m                latent = self.action_ae.encode_into_latent(act, enc_obs)
[1m    129 [22m                _, loss, loss_components = self.state_prior.get_latent_and_loss(
[1m    130 [22m                    obs_rep=enc_obs,
[1m    131 [22m                    target_latents=latent,
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?ipdb> n
[?7h[?12l[?25h[?2004l> /nfs/kun2/users/asap7772/bet/exp_local/2022.08.23/212350_bridge_data/train.py(127)train_prior()
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ln[?7h[?12l[?25h[?ipdb> n
[?7h[?12l[?25h[?2004lRuntimeError: The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 0
> /nfs/kun2/users/asap7772/bet/exp_local/2022.08.23/212350_bridge_data/train.py(127)train_prior()
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?ipdb> l
[?7h[?12l[?25h[?2004l[1m    122 [22m            for data in pbar:
[1m    123 [22m                import ipdb; ipdb.set_trace()
[1m    124 [22m                observations, action, mask, task = data
[1m    125 [22m                self.state_prior_optimizer.zero_grad(set_to_none=True)
[1m    126 [22m                obs, act = observations.to(self.device), action.to(self.device)
--> 127                 enc_obs = self.obs_encoding_net(obs)
[1m    128 [22m                latent = self.action_ae.encode_into_latent(act, enc_obs)
[1m    129 [22m                _, loss, loss_components = self.state_prior.get_latent_and_loss(
[1m    130 [22m                    obs_rep=enc_obs,
[1m    131 [22m                    target_latents=latent,
[1m    132 [22m                    return_loss_components=True,
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?2ipdb>
Training prior: :   0%|                                                                                                                                                                                                                                                                        | 0/40 [00:49<?, ?it/s]
Error executing job with overrides: []
Traceback (most recent call last):
  File "train.py", line 285, in main
    workspace.run()
  File "train.py", line 184, in run
    self.train_prior()
  File "train.py", line 127, in train_prior
    enc_obs = self.obs_encoding_net(obs)
  File "/home/asap7772/miniconda3/envs/behavior-transformer/lib/python3.8/bdb.py", line 94, in trace_dispatch
    return self.dispatch_exception(frame, arg)
  File "/home/asap7772/miniconda3/envs/behavior-transformer/lib/python3.8/bdb.py", line 174, in dispatch_exception
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.