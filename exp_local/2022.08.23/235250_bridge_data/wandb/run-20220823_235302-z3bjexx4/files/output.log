done step 1/50, re-initialized 8 dead clusters
[2022-08-23 23:53:10,615][models.libraries.mingpt.model][INFO] - number of parameters: 2.634752e+06
K-means clustering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 150.02it/s]
Training prior: :   0%|                                                                                                                                          | 0/40 [00:00<?, ?it/s]
Training prior epoch 0:   0%|                                                                                                                                     | 0/8 [00:00<?, ?it/s]
> /nfs/kun2/users/asap7772/bet/exp_local/2022.08.23/235250_bridge_data/train.py(127)train_prior()

[?2004h[?1l[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?ipdb> l
[?7h[?12l[?25h[?2004l[1m    122 [22m            for data in pbar:
[1m    123 [22m                observations, action, mask, task = data
[1m    124 [22m                self.state_prior_optimizer.zero_grad(set_to_none=True)
[1m    125 [22m                obs, act = observations.to(self.device), action.to(self.device)
[1m    126 [22m                import ipdb; ipdb.set_trace()
--> 127                 if obs.ndim != 3:
[1m    128 [22m                    enc_obs = self.obs_encoding_net(obs)
[1m    129 [22m                else:
[1m    130 [22m                    enc_obs = obs
[1m    131 [22m                latent = self.action_ae.encode_into_latent(act, enc_obs)
[1m    132 [22m                _, loss, loss_components = self.state_prior.get_latent_and_loss(

[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7lo[?7h[?12l[?25h[?25l[?7lb[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7l.[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7lha[?7h[?12l[?25h[?25l[?7lp[?7h[?12lipdb> obs.shape
[?7h[?12l[?25h[?2004ltorch.Size([128, 10, 512])
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7lt[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lsk.[?7h[?12l[?25h[?25l[?7lsh[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lp[?7h[?12ipdb> task.shape
[?7h[?12l[?25h[?2004ltorch.Size([128, 10, 2])

[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?ipdb> l
[?7h[?12l[?25h[?2004l[1m    133 [22m                    obs_rep=enc_obs,
[1m    134 [22m                    target_latents=latent,
[1m    135 [22m                    return_loss_components=True,
[1m    136 [22m                )
[1m    137 [22m                loss.backward()
[1m    138 [22m                torch.nn.utils.clip_grad_norm_(
[1m    139 [22m                    self.state_prior.parameters(), self.cfg.grad_norm_clip
[1m    140 [22m                )
[1m    141 [22m                self.state_prior_optimizer.step()
[1m    142 [22m                self.log_append("prior_train", len(observations), loss_components)
[1m    143 
Training prior: :   0%|                                                                                                                                          | 0/40 [02:18<?, ?it/s]
Error executing job with overrides: []
[?7h[?12l[?25h[?2004l
Traceback (most recent call last):
  File "train.py", line 291, in main
    workspace.run()
  File "train.py", line 190, in run
    self.train_prior()
  File "train.py", line 127, in train_prior
    enc_obs = self.obs_encoding_net(obs)
  File "train.py", line 127, in train_prior
    enc_obs = self.obs_encoding_net(obs)
  File "/home/asap7772/miniconda3/envs/behavior-transformer/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/asap7772/miniconda3/envs/behavior-transformer/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.