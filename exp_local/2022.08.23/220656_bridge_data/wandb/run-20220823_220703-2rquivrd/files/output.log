K-means clustering: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 199.70it/s]
Training prior: :   0%|                                                                                                                                          | 0/40 [00:00<?, ?it/s]
Training prior epoch 0:   0%|                                                                                                                                     | 0/8 [00:00<?, ?it/s]
done step 1/50, re-initialized 8 dead clusters
[2022-08-23 22:07:10,448][models.libraries.mingpt.model][INFO] - number of parameters: 2.634752e+06
> /nfs/kun2/users/asap7772/bet/exp_local/2022.08.23/220656_bridge_data/train.py(137)train_prior()

[?2004h[?1l[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?25l[?7lo[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25ipdb> loss
[?7h[?12l[?25h[?2004ltensor(54.6672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)


[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?25l[?7lo[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7ls[?7h[?12l[?25h[?25l[?7l.[?7h[?12l[?25h[?25l[?7lf[?7h[?12l[?25h[?25l[?7ll[?7h[?12l[?25h[?25l[?7lo[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lt[?7h[?12l[?25h[?25l[?7l([?7h[?12l[?25h[?25l[?7l)[?7h[ipdb> loss.float()
[?7h[?12l[?25h[?2004ltensor(54.6672, device='cuda:0', grad_fn=<ToCopyBackward0>)

[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7lloss.float()[?7h[?12l[?25h[?25l[?7l.[?7h[?12l[?25h[?25l[?7lb[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lc[?7h[?12l[?25h[?25l[?7lk[?7h[?12l[?25h[?25l[?7lw[?7h[?12l[?25h[?25l[?7la[?7h[?12l[?25h[?25l[?7lr[?7h[?12l[?25h[?25l[?7ld[?7h[?12l[?25h[?25l[?7l([?7h[?12l[?25h[?25ipdb> loss.float().backward()
[?7h[?12l[?25h[?2004l*** RuntimeError: Found dtype Double but expected Float



Training prior: :   0%|                                                                                                                                          | 0/40 [00:57<?, ?it/s]
Error executing job with overrides: []
[?7h[?12l[?25h[?2004l*** RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
[?2004h[?25l[?7lipdb> [?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?25l[?7l[?7h[?12l[?25h[?2ipdb>
[?7h[?12l[?25h[?2004l
Traceback (most recent call last):
  File "train.py", line 288, in main
  File "train.py", line 187, in run
    if ((self.prior_epoch + 1) % self.cfg.eval_prior_every) == 0:
  File "train.py", line 137, in train_prior
    torch.nn.utils.clip_grad_norm_(
  File "train.py", line 137, in train_prior
    torch.nn.utils.clip_grad_norm_(
  File "/home/asap7772/miniconda3/envs/behavior-transformer/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/asap7772/miniconda3/envs/behavior-transformer/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.